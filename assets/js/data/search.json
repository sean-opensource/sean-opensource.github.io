[ { "title": "Linear Regression with Multiple Variables in Python", "url": "/posts/pyhon-Linear-Regression-with-Multiple-Variab/", "categories": "Python, AI", "tags": "post", "date": "2024-06-25 00:00:00 +1000", "snippet": "Linear Regression with Multiple Variables in Python: A Detailed GuideLinear regression is a fundamental technique in machine learning and statistics. It is used to predict a continuous target variable based on one or more input features. When multiple variables (features) are involved, it’s called multiple linear regression. In this blog post, we will go through the steps to implement multiple linear regression in Python, using the popular scikit-learn library.Table of Contents Introduction Prerequisites Step-by-Step Guide Data Preparation Data Visualization Feature Selection Splitting Data Training the Model Making Predictions Model Evaluation ConclusionIntroductionMultiple linear regression aims to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. The equation for multiple linear regression looks like this:[ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n + \\epsilon ]Where: ( y ) is the dependent variable (target). ( x_1, x_2, \\ldots, x_n ) are the independent variables (features). ( \\beta_0 ) is the intercept. ( \\beta_1, \\beta_2, \\ldots, \\beta_n ) are the coefficients. ( \\epsilon ) is the error term.PrerequisitesBefore we start, make sure you have the following packages installed: pandas numpy matplotlib scikit-learnYou can install these packages using pip:pip install pandas numpy matplotlib scikit-learnStep-by-Step Guide1. Data PreparationFirst, we need to load and prepare our dataset. For this example, we’ll use a dataset with house prices which includes features like square footage, number of bedrooms, and age of the house.import pandas as pd# Load the datasetdata = pd.read_csv('house_prices.csv')# Display the first few rows of the datasetprint(data.head())2. Data VisualizationVisualizing the data helps in understanding the relationships between variables.import matplotlib.pyplot as plt# Scatter plot for each feature against the target variableplt.figure(figsize=(10, 8))plt.subplot(2, 2, 1)plt.scatter(data['square_footage'], data['price'])plt.title('Price vs Square Footage')plt.xlabel('Square Footage')plt.ylabel('Price')plt.subplot(2, 2, 2)plt.scatter(data['bedrooms'], data['price'])plt.title('Price vs Bedrooms')plt.xlabel('Bedrooms')plt.ylabel('Price')plt.subplot(2, 2, 3)plt.scatter(data['age'], data['price'])plt.title('Price vs Age')plt.xlabel('Age')plt.ylabel('Price')plt.tight_layout()plt.show()3. Feature SelectionSelecting relevant features is crucial for building a good model. For this example, we’ll use all available features.4. Splitting DataSplit the data into training and testing sets.from sklearn.model_selection import train_test_split# Features and target variableX = data[['square_footage', 'bedrooms', 'age']]y = data['price']# Split the dataset into training and testing setsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)5. Training the ModelTrain the linear regression model using the training data.from sklearn.linear_model import LinearRegression# Create the modelmodel = LinearRegression()# Train the modelmodel.fit(X_train, y_train)6. Making PredictionsUse the trained model to make predictions on the test set.# Make predictions on the test sety_pred = model.predict(X_test)7. Model EvaluationEvaluate the model’s performance using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score# Calculate evaluation metricsmae = mean_absolute_error(y_test, y_pred)mse = mean_squared_error(y_test, y_pred)r2 = r2_score(y_test, y_pred)# Print the evaluation metricsprint(f'Mean Absolute Error: {mae}')print(f'Mean Squared Error: {mse}')print(f'R-squared: {r2}')ConclusionMultiple linear regression is a powerful tool for predicting outcomes based on multiple features. By following the steps outlined in this guide, you can build and evaluate a multiple linear regression model using Python. The scikit-learn library makes it straightforward to implement and assess machine learning models.Remember, the key to a good model is not just in the algorithm itself but also in the quality and preparation of the data. Happy coding!+++" }, { "title": "Copy ADFS Claim Rules", "url": "/posts/ADFS-powershell/", "categories": "Powrshell, ADFS", "tags": "post", "date": "2024-06-24 00:00:00 +1000", "snippet": "Copy ADFS Claim Rules with PowerShellIn our infrastructure, we frequently configure ADFS relying party trusts for various environments, including Dev, QA, and Lab instances of Microsoft CRM. The manual entry of claim rules for each trust is both time-consuming and error-prone. To streamline this process, I developed a PowerShell script to automate the export and import of ADFS claim rules, significantly enhancing efficiency and consistency.Export ADFS Claim RulesFirst, export the claim rules to a file from an existing ADFS Relying Party Trust. You only need the Issuance Transform Rules.# Define the name of the existing relying party trust$existingRelyingPartyTrustName = \"WOPR - External\"# Define the output file path$outputFilePath = \"C:\\temp\\Claim_Rules.txt\"# Check if the output file already exists and delete it if it doesif (Test-Path $outputFilePath) { Remove-Item $outputFilePath}# Export the claim rules to the fileGet-ADFSRelyingPartyTrust -Name $existingRelyingPartyTrustName | Select-Object -ExpandProperty IssuanceTransformRules | Out-File $outputFilePath -Force# Confirm the file has been createdif (Test-Path $outputFilePath) { Write-Output \"Claim rules successfully exported to $outputFilePath\"} else { Write-Output \"Failed to export claim rules.\"}Import ADFS Claim RulesOnce you have the rules stored in a text file, you can import them into your new relying party trust.# Define the name of the new relying party trust$newRelyingPartyTrustName = \"NORAD - External\"# Define the path to the file containing the claim rules$importFilePath = \"C:\\temp\\Claim_Rules.txt\"# Check if the file exists before attempting to importif (Test-Path $importFilePath) { # Import the claim rules from the file Set-ADFSRelyingPartyTrust -TargetName $newRelyingPartyTrustName -IssuanceTransformRulesFile $importFilePath # Verify the rules were imported $importedRules = Get-ADFSRelyingPartyTrust -Name $newRelyingPartyTrustName | Select-Object -ExpandProperty IssuanceTransformRules if ($importedRules) { Write-Output \"Claim rules successfully imported to $newRelyingPartyTrustName\" } else { Write-Output \"Failed to import claim rules.\" }} else { Write-Output \"Claim rules file not found at $importFilePath\"}Explanation and Error Handling Export ADFS Claim Rules: The script starts by defining the name of the existing relying party trust and the output file path. It checks if the output file already exists and deletes it if it does to ensure a clean export. The Get-ADFSRelyingPartyTrust cmdlet retrieves the claim rules, which are then saved to the specified file. It verifies if the export was successful by checking if the file was created. Import ADFS Claim Rules: The script defines the name of the new relying party trust and the path to the import file. It checks if the import file exists before attempting to import the claim rules. The Set-ADFSRelyingPartyTrust cmdlet imports the rules from the file into the new relying party trust. It verifies the import by retrieving the rules from the new relying party trust and checking if they are present. This approach ensures robust error handling and provides feedback at each step, making it easier to identify and resolve issues." }, { "title": "Running Open-Source Large Language Models Locally with Python", "url": "/posts/pyhon-AI/", "categories": "Python, AI", "tags": "post", "date": "2024-06-24 00:00:00 +1000", "snippet": "Using Open-Source Large Language Models Locally with PythonLarge language models (LLMs) have revolutionized natural language processing (NLP) by providing advanced capabilities for text generation, translation, summarization, and more. While cloud-based solutions are popular, running these models locally offers significant advantages such as enhanced privacy, data control, and reduced latency. In this guide, we’ll walk you through the steps to set up and use open-source LLMs locally with Python.PrerequisitesBefore we begin, ensure you have the following: A computer with sufficient hardware (16GB+ RAM recommended). Python installed (Python 3.7 or later). Basic knowledge of Python and the command-line interface.Step 1: Setting Up the EnvironmentFirst, let’s set up a Python virtual environment to manage our dependencies. This helps keep our project isolated and avoids conflicts with other projects. Create a virtual environment: python -m venv llm_env Activate the virtual environment: On Windows: .\\llm_env\\Scripts\\activate On macOS/Linux: source llm_env/bin/activate Step 2: Installing Required LibrariesWe’ll use the transformers library from Hugging Face, which provides easy access to various LLMs, and torch, which is a deep learning framework required by many models. Upgrade pip and install transformers and torch: pip install --upgrade pip pip install transformers torch Step 3: Downloading the ModelFor this guide, we’ll use GPT-2, a well-known model developed by OpenAI. The process is similar for other models available on the Hugging Face Model Hub. Create a Python script to download the model: # download_model.py from transformers import GPT2LMHeadModel, GPT2Tokenizer # Load pre-trained model and tokenizer model_name = 'gpt2' model = GPT2LMHeadModel.from_pretrained(model_name) tokenizer = GPT2Tokenizer.from_pretrained(model_name) # Save the model and tokenizer to local directory model.save_pretrained('./gpt2') tokenizer.save_pretrained('./gpt2') print(\"Model and tokenizer downloaded and saved locally.\") Run the script: python download_model.py Step 4: Running the Model LocallyWith the model downloaded, we can now run it locally. We’ll create a simple script to generate text based on a user-provided prompt. Create a Python script for text generation: # generate_text.py from transformers import GPT2LMHeadModel, GPT2Tokenizer # Load the locally saved model and tokenizer model = GPT2LMHeadModel.from_pretrained('./gpt2') tokenizer = GPT2Tokenizer.from_pretrained('./gpt2') # Function to generate text def generate_text(prompt, max_length=50): inputs = tokenizer.encode(prompt, return_tensors='pt') outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1) text = tokenizer.decode(outputs[0], skip_special_tokens=True) return text # Get user prompt prompt = input(\"Enter a prompt: \") # Generate and print text generated_text = generate_text(prompt) print(\"Generated Text: \", generated_text) Run the script: python generate_text.py ConclusionRunning large language models locally using Python is a powerful way to leverage AI capabilities while maintaining control over your data and environment. This guide provided a step-by-step process to set up, download, and run an open-source model. With these skills, you can experiment with various models and integrate them into your projects seamlessly.For further exploration, consider experimenting with different models available on the Hugging Face Model Hub and adjusting parameters like max_length and num_return_sequences to fine-tune the generated output to your needs.Feel free to customize and expand this guide as you explore the capabilities of large language models!You can save the content above in a file named use_llms_locally.md. This markdown file provides a comprehensive guide for setting up and running open-source large language models locally using Python." }, { "title": "Windows Subsystem for Linux (WSL) setup", "url": "/posts/WSL-setup-for-python/", "categories": "Python, WSL", "tags": "post", "date": "2024-06-24 00:00:00 +1000", "snippet": "Using Python in Windows WSL: A Detailed GuideWith Windows Subsystem for Linux (WSL), you can run a Linux distribution alongside your Windows installation, allowing you to enjoy the best of both worlds. This guide will walk you through the process of setting up WSL, installing Python, and running Python scripts in a WSL environment.PrerequisitesBefore starting, ensure you have: A Windows 10 (version 2004 and higher) or Windows 11 system. Basic knowledge of command-line interfaces.Step 1: Installing WSLFirst, you need to install WSL on your Windows machine. Follow these steps: Open PowerShell as Administrator: Press Win + X and select Windows PowerShell (Admin). Enable WSL: wsl --install This command will enable the necessary features and install a default Linux distribution (usually Ubuntu). Restart your computer if prompted. Verify Installation: After restarting, open a new PowerShell window and check the WSL version: wsl -l -v You should see your installed Linux distribution listed. Step 2: Setting Up a Linux DistributionIf you installed the default Ubuntu distribution, you can proceed with setting it up. If you want to install a different distribution, follow these steps: List Available Distributions: wsl --list --online Install a Distribution: wsl --install -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the distribution you want to install. Launch and Set Up the Distribution: Open your installed distribution from the Start menu or by typing wsl in PowerShell. Follow the on-screen instructions to set up your username and password. Step 3: Installing PythonNow that you have your Linux distribution set up, you can install Python. Update Package List: Open your WSL terminal and run: sudo apt update Install Python: sudo apt install python3 python3-pip Verify Installation: Check the installed Python version: python3 --version Step 4: Running a Python ScriptLet’s create and run a simple Python script to ensure everything is working correctly. Create a Python Script: In your WSL terminal, create a new file: nano hello.py Add the following content: print(\"Hello, WSL!\") Save and exit the editor (Ctrl + X, then Y, then Enter). Run the Script: Execute the script using Python: python3 hello.py You should see the output Hello, WSL!. ConclusionBy following this guide, you’ve set up WSL on your Windows machine, installed a Linux distribution, and successfully installed and run Python. This setup allows you to leverage the power of Linux development tools while working within your Windows environment. Explore further by installing additional Python packages, setting up virtual environments, and developing your projects in this flexible setup." }, { "title": "Welcome", "url": "/posts/welcome/", "categories": "Powershell", "tags": "post", "date": "2022-06-14 00:33:00 +1000", "snippet": "WelcomeHello and welcome to my script docs site.Adding a new network drive with New-PSDriveRequired parameters to create a network connection:Parameter\tDescriptionName\tMust be an available drive letterPSProvider\tSet to FileSystem for network shares and foldersRoot\tThe network location that you want to mapPersist\tTo make it available outside PowerShell (in Explorer)New-PSDrive -Name V -PSProvider FileSystem -Root \\\\VM-server\\Folder-01 -Persist" } ]
